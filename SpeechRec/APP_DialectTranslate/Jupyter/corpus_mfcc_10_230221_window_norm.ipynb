{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "from dtw import dtw\n",
    "from numpy.linalg import norm\n",
    "from numpy import array\n",
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialCorpus(path):\n",
    "    # 音乐库位置\n",
    "    audioList = os.listdir(path)\n",
    "\n",
    "    raw_audioList = {}\n",
    "    beat_database = {}\n",
    "\n",
    "    for tmp in audioList:\n",
    "        audioName = os.path.join(path, tmp)\n",
    "        if audioName.endswith('.wav'):\n",
    "            # 读入一维音频序列\n",
    "            y, sr = librosa.load(audioName)\n",
    "            # 提取 MFCC 特征\n",
    "            f = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=10)\n",
    "            # 存入数据表\n",
    "            beat_database[audioName] = f\n",
    "\n",
    "    # 保存音乐节奏数据库\n",
    "    np.save('beatDatabase_mfcc.npy', beat_database)\n",
    "    \n",
    "    return beat_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCorpus(path):\n",
    "    \n",
    "    # 读入音乐节奏数据库\n",
    "    all_data = np.load(path, allow_pickle=True)\n",
    "    beat_database = all_data.item()\n",
    "    \n",
    "    return beat_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateCorpus(path, dbpath):\n",
    "    \n",
    "    # 音乐库位置\n",
    "    audioList = os.listdir(path)\n",
    "    \n",
    "    # 已保存序列的文件\n",
    "    raw_db = readCorpus(dbPath)\n",
    "    raw_files = raw_db.keys()\n",
    "    \n",
    "    for tmp in audioList:\n",
    "        audioName = os.path.join(path, tmp)\n",
    "        if audioName.endswith('.wav') and audioName not in raw_files:\n",
    "            y, sr = librosa.load(audioName)\n",
    "            # 提取 MFCC 特征\n",
    "            f = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=10)\n",
    "            # 存入数据表\n",
    "            beat_database[audioName] = f\n",
    "\n",
    "    # 保存音乐节奏数据库\n",
    "    np.save(dbpath, beat_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voiceCompare_quick(dbPath, tPath):\n",
    "    \n",
    "    # 读入语料库\n",
    "    all_data = np.load(dbPath, allow_pickle=True)\n",
    "    beat_database = all_data.item()\n",
    "\n",
    "    # 读入要识别的录音\n",
    "    y, sr = librosa.load(tPath)\n",
    "\n",
    "    # 识别录音的节奏序列\n",
    "    tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    beat_frames = librosa.feature.delta(beat_frames,mode ='nearest')\n",
    "    x = array(beat_frames).reshape(-1, 1)\n",
    "\n",
    "    # 将待识别的录音序列与语料库中语音逐一做DTW对比\n",
    "    compare_result = {}\n",
    "    \n",
    "    for songID in beat_database.keys():\n",
    "        y = beat_database[songID]\n",
    "        y = array(y).reshape(-1, 1)\n",
    "        \n",
    "        dist = dtw(x, y).distance\n",
    "        # print('两段话的差异程度为： ', songID.split(\"\\\\\")[1], \": \", dist)\n",
    "        \n",
    "        compare_result[songID] = dist\n",
    "\n",
    "    matched_song = min(compare_result, key=compare_result.get)\n",
    "    print(\"最接近的录音是：\", matched_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normlize(data):\n",
    "    n_mean = np.mean(data, axis=0)\n",
    "    n_std  = np.std(data, axis=0)\n",
    "    \n",
    "    norm_data = np.divide(np.subtract(data, n_mean), n_std)\n",
    "    return norm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def voiceCompare(dbPath, tPath):\n",
    "    # ==== 最大检索数 ====\n",
    "    aimNum = 20\n",
    "    \n",
    "    # 读入语料库\n",
    "    all_data = np.load(dbPath, allow_pickle=True)\n",
    "    beat_database = all_data.item()\n",
    "\n",
    "    # ==== 读入要识别的录音 ====\n",
    "    y, sr = librosa.load(tPath)\n",
    "\n",
    "    # 提取录音的 MFCC 特征\n",
    "    # x = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=10).T  # n1 * 10\n",
    "    x = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=10)  # 10 * n1\n",
    "    lenx = len(x[0])\n",
    "    \n",
    "    # 归一化\n",
    "    #for i in range(0, lenx):\n",
    "    #    x[i] = preprocessing.minmax_scale(x[i])\n",
    "    \n",
    "    # 标准化\n",
    "    x = x.T\n",
    "    for i in range(0, lenx):\n",
    "        x[i] = normlize(x[i])\n",
    "    x = x.T\n",
    "    \n",
    "\n",
    "    # ==== 将待识别的录音序列与语料库中语音逐一做DTW对比 ====\n",
    "    \n",
    "    # heap for [dist, 时间段，文件名]\n",
    "    heap = []\n",
    "    heapq.heapify(heap)  \n",
    "    \n",
    "    for songID in beat_database.keys():\n",
    "        # 取出文件名对应的 mfcc 序列\n",
    "        # y = beat_database[songID].T\n",
    "        y = beat_database[songID]\n",
    "        \n",
    "        leny = len(y[0]) # 10 * n2 \n",
    "        print(leny)\n",
    "        \n",
    "        # 归一化\n",
    "        #for i in range(0, 10):\n",
    "        #    y[i] = preprocessing.minmax_scale(y[i])\n",
    "        \n",
    "        # 标准化\n",
    "        y = y.T\n",
    "        for i in range(0, leny):\n",
    "            y[i] = normlize(y[i])\n",
    "        y = y.T\n",
    "\n",
    "        for tp in range(0, leny - lenx):\n",
    "            # *加速* 设定距离上限\n",
    "            full = False  # 堆是否已满\n",
    "            dist_UB = -10000  # DTW 距离上限\n",
    "            overBound = False  # 是否过限\n",
    "            \n",
    "            if (len(heap) >= aimNum):\n",
    "                full = True\n",
    "                dist_UB = -heap[0][0]  # heap top (biggest) DTW dist as UB  \n",
    "                \n",
    "            # 计算 DTW(y[tp : tp + lenx])\n",
    "            total_dist = 0\n",
    "            \n",
    "            for i in range(0, 10):\n",
    "                # DTW dist\n",
    "                total_dist += dtw(x[i], y[i][tp : tp + lenx], distance_only=False).distance\n",
    "                \n",
    "                # *加速* 超过上限直接取消\n",
    "                if (full and total_dist > dist_UB):\n",
    "                    overBound = True\n",
    "                    break\n",
    "            \n",
    "            # *加速* 超过上限\n",
    "            if (overBound):\n",
    "                continue\n",
    "            \n",
    "            # 入栈\n",
    "            tupleY = (-total_dist, tp, songID) # dtw 距离加负数转为大根堆\n",
    "            \n",
    "            heapq.heappush(heap, tupleY)\n",
    "            if (len(heap) > aimNum):\n",
    "                heapq.heappop(heap)\n",
    "            \n",
    "            print(tupleY)\n",
    "            \n",
    "        # end for\n",
    "        \n",
    "        # 处理同名短间隔问题\n",
    "        \n",
    "        \n",
    "    return heap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimePoint_dense(dbPath, tPath, vheap):\n",
    "    res_num = 20 # 定义取出前 res_num 位的结果作为识别结果\n",
    "    \n",
    "    # 读入语料库\n",
    "    all_data = np.load(dbPath, allow_pickle=True)\n",
    "    beat_database = all_data.item()\n",
    "    \n",
    "    # 得到要识别的录音时长\n",
    "    tTime = librosa.get_duration(filename=tPath)\n",
    "    \n",
    "    # 提取前 res_num 个相似的片段并输出对应时间段\n",
    "    similar_n = heapq.nlargest(res_num, vheap)\n",
    "    \n",
    "    print(\"开始输出相似片段：\")\n",
    "    \n",
    "    for i in range(0, res_num):\n",
    "        music_name = similar_n[i][2]  # 录音文件名\n",
    "        music_time = librosa.get_duration(filename=music_name)  # 录音时长\n",
    "        \n",
    "        music_pos = similar_n[i][1]  # 时间段所在帧数\n",
    "        music_all = len(beat_database[music_name][0])  # 录音总帧数\n",
    "\n",
    "        frag_st = music_time / music_all * music_pos  # 时间段起点\n",
    "        frag_en = frag_st + tTime  # 时间段终点\n",
    "        \n",
    "        # print(music_name, music_time, music_pos, music_all, frag_st)\n",
    "        # print(\"相似度第\", i + 1, \"位的为文件 \", music_name, \"的 \", '%.2f' % frag_st, \"到\", '%.2f' % frag_en, \"秒\")\n",
    "        \n",
    "        print(music_name, \",\", '%.2f' % frag_st, \"秒,\", '%.2f' % frag_en, \"秒\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimePoint(dbPath, tPath, vheap):\n",
    "    # 读入语料库\n",
    "    all_data = np.load(dbPath, allow_pickle=True)\n",
    "    beat_database = all_data.item()\n",
    "    \n",
    "    # 得到要识别的录音时长\n",
    "    tTime = librosa.get_duration(filename=tPath)\n",
    "    \n",
    "    heapq.nlargest(20, vheap)\n",
    "    \n",
    "    # ====== 对 vheap 进行去重 ======\n",
    "    # 取出文件名\n",
    "    name_set = set()\n",
    "    for tp in vheap:\n",
    "        name_set.add(tp[2])\n",
    "    # print(name_set)\n",
    "    \n",
    "    # 合并下标差小于5的片段\n",
    "    sheap = []\n",
    "    for name in name_set:\n",
    "        # 按下标排序\n",
    "        nList = [x for x in vheap if x[2] == name]\n",
    "        sortL = sorted(nList, key=lambda t:t[1])\n",
    "        \n",
    "        # 去重\n",
    "        for tp in sortL:\n",
    "            if len(sheap) < 1 or sheap[-1][2] != name or abs(sheap[-1][1] - tp[1]) > 5:\n",
    "                sheap.append(tp)\n",
    "            else:  \n",
    "                if (sheap[-1][0] < tp[0]): \n",
    "                    sheap[-1] = tp  # 保留距离较小项\n",
    "\n",
    "    # print(sheap)\n",
    "    # 提取相似片段并输出对应时间段\n",
    "    similar_n = sheap\n",
    "    \n",
    "    print(\"开始输出相似片段：\")\n",
    "    \n",
    "    for i in range(0, len(sheap)):\n",
    "        music_name = similar_n[i][2]  # 录音文件名\n",
    "        music_time = librosa.get_duration(filename=music_name)  # 录音时长\n",
    "        \n",
    "        music_pos = similar_n[i][1]  # 时间段所在帧数\n",
    "        music_all = len(beat_database[music_name][0])  # 录音总帧数\n",
    "\n",
    "        frag_st = music_time / music_all * music_pos  # 时间段起点\n",
    "        frag_en = frag_st + tTime  # 时间段终点\n",
    "        \n",
    "        # print(music_name, music_time, music_pos, music_all, frag_st)\n",
    "        # print(\"相似度第\", i + 1, \"位的为文件 \", music_name, \"的 \", '%.2f' % frag_st, \"到\", '%.2f' % frag_en, \"秒\")\n",
    "        \n",
    "        print(music_name, \",\", '%.2f' % frag_st, \"秒,\", '%.2f' % frag_en, \"秒\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 语料库路径\n",
    "corpus_path = './corpus'\n",
    "\n",
    "# 数据表路径\n",
    "dbPath = './beatDatabase_mfcc.npy';\n",
    "\n",
    "# test file path\n",
    "testPath = './input/00430105-hou5s.wav'\n",
    "# testPath = './input/00415250-前5s.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1 初始化语料序列库\n",
    "# beatDB = initialCorpus(corpus_path)\n",
    "\n",
    "# 2 更新语料库中新音乐文件的序列\n",
    "# updateCorpus(corpus_path, dbPath)\n",
    "\n",
    "# 3 读入语料序列库\n",
    "# beat_database = readCorpus(dbPath)\n",
    "\n",
    "# vheap = voiceCompare(dbPath, testPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getTimePoint(dbPath, testPath, vheap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inPara = sys.argv\n",
    "\n",
    "if (len(inPara) < 2):\n",
    "    print(\"请输入待识别录音文件路径！\")\n",
    "else:\n",
    "    if (len(inPara) > 2):\n",
    "        print(\"给定语料库路径为:\", sys.argv[2])\n",
    "        corpus_path = sys.argv[2]\n",
    "    else:\n",
    "        print(\"默认语料库路径为：\", corpus_path)\n",
    "    \n",
    "    if (len(inPara) > 3):\n",
    "        print(\"给定数据表路径为:\", sys.argv[3])\n",
    "        dbPath = sys.argv[3]\n",
    "    else:\n",
    "        print(\"默认数据表路径为：\", dbPath)\n",
    "    \n",
    "    testPath = sys.argv[1]\n",
    "    vheap = voiceCompare(dbPath, testPath)\n",
    "    getTimePoint(dbPath, testPath, vheap)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
